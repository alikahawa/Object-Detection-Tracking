{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking Objects in Video with Particle Filters\n",
    "==============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Repeatability\n",
    "np.random.seed(0)\n",
    "\n",
    "VFILENAME = \"walking.mp4\"\n",
    "HEIGHT = 406\n",
    "WIDTH = 722"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load video frames from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(filename):\n",
    "    video = cv2.VideoCapture(filename)\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if ret:\n",
    "            yield frame\n",
    "        else:\n",
    "            break\n",
    "    video.release()\n",
    "    yield None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators are iterators, a kind of iterable you can only iterate over once. \n",
    "###### Generators do not store all the values in memory, they generate the values on the fly\n",
    "example:  `mygenerator = (x*x for x in range(3))`\n",
    "\n",
    "##### yield is a keyword that is used like return, except the function will return a generator.\n",
    "\n",
    "The first time the for calls the generator object created from your function, it will run the code in your function from the beginning until it hits yield, then it'll return the first value of the loop. \n",
    "\n",
    "Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting yield. \n",
    "\n",
    "That can be because the loop has come to an end, or because you no longer satisfy an \"if/else\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a particle cloud\n",
    "\n",
    "Initialize particle filter and display it on top of our video frames\n",
    "\n",
    "We'll have a random velocity (uniformly distributed) because we don't know where the target is at the begining.\n",
    "\n",
    "our goal is to estimate the state of the target, meaning\n",
    "its position and velocity within the video frames.\n",
    "At the beginning of the video,\n",
    "we don't know that state.\n",
    "All we know is that the position should lie within the frame\n",
    "somewhere, and the velocity could be in any direction but not\n",
    "moving too, too fast.\n",
    "We are going to express our estimate of the target state\n",
    "with a set of particles.\n",
    "Each particle has its own position and velocity.\n",
    "And at the beginning of the video, since we have\n",
    "no information yet about the target, our particles\n",
    "will be scattered uniformly in the frame and they'll have\n",
    "random velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PARTICLES = 5000 # 50\n",
    "VEL_RANGE = 0.5\n",
    "def initialize_particles():\n",
    "    particles = np.random.rand(NUM_PARTICLES, 4)\n",
    "    \"\"\"\n",
    "    We're going to multiply this array, and the first column\n",
    "    is going to represent the x position.\n",
    "    We want to scale it up to the width of our frame.\n",
    "    The second column will have the y position.\n",
    "    We want to scale that up to the height of our frame.\n",
    "    And the two other columns will be the x and y velocity\n",
    "    components.\n",
    "    So here we're actually scaling them down to the initial range\n",
    "    of velocities that we're expecting.\n",
    "    \"\"\"\n",
    "    particles = particles * np.array( (WIDTH,HEIGHT,VEL_RANGE,VEL_RANGE) )\n",
    "    # we want the velocity to be centred at zero because \n",
    "    # we want to have the possiblity of having he velocity at any direction\n",
    "    # it might then be positive or negative\n",
    "    particles[ :, 2:4 ] -= VEL_RANGE/2.0 # Center velocities around 0\n",
    "    return particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving particles according to their velocity state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_velocity(particles):\n",
    "    particles[ :, 0 ] += particles[ :, 2 ]  # x = x + u\n",
    "    particles[ :, 1 ] += particles[ :, 3 ]\n",
    "    return particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prevent particles from falling off the edge of the video frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_edges(particles):\n",
    "    for i in range(NUM_PARTICLES):\n",
    "        particles[i,0] = max(0, min(WIDTH-1, particles[i,0]))\n",
    "        particles[i,1] = max(0, min(HEIGHT-1, particles[i,1]))\n",
    "    return particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure each particle's quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(particles, frame):\n",
    "    errors = np.zeros(NUM_PARTICLES)\n",
    "    TARGET_COLOUR = np.array( (189,105,82) ) # Blue top sleeve pixel colour\n",
    "#    TARGET_COLOUR = np.array( (148, 73, 49) ) # Blue top sleeve pixel colour\n",
    "    for i in range(NUM_PARTICLES):\n",
    "        x = int(particles[i,0])\n",
    "        y = int(particles[i,1])\n",
    "        pixel_colour = frame[ y, x, : ]\n",
    "        errors[i] = np.sum( ( TARGET_COLOUR - pixel_colour )**2 ) # MSE in colour space\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign weights to the particles based on their quality of match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(errors):\n",
    "    weights = np.max(errors) - errors\n",
    "    weights[ \n",
    "        (particles[ :,0 ] == 0) |\n",
    "        (particles[ :,0 ] == WIDTH-1) |\n",
    "        (particles[ :,1 ] == 0) |\n",
    "        (particles[ :,1 ] == HEIGHT-1)\n",
    "    ] = 0.0\n",
    "    \n",
    "    # Make weights more sensitive to colour difference.\n",
    "    # Cubing a set of numbers in the interval [0,1], the farther a number is from 1, the more it gets squashed toward zero\n",
    "    weights = weights**4\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample particles according to their weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(particles, weights):\n",
    "    # Normalize to get valid PDF\n",
    "    probabilities = weights / np.sum(weights)\n",
    "\n",
    "    # Resample\n",
    "    indices = np.random.choice(\n",
    "        NUM_PARTICLES,\n",
    "        size=NUM_PARTICLES,\n",
    "        p=probabilities)\n",
    "    particles = particles[ indices, : ]\n",
    "\n",
    "    # Take average over all particles, best-guess for location\n",
    "    x = np.mean(particles[:,0])\n",
    "    y = np.mean(particles[:,1])\n",
    "    return particles, (int(x),int(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzz the particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_noise(particles):\n",
    "    # Noise is good!  Noise expresses our uncertainty in the target's position and velocity\n",
    "    # We add small variations to each hypothesis that were samples from the best ones in last iteration.\n",
    "    # The target's position and velocity may have changed since the last frame, some of the fuzzed hypotheses will match these changes.\n",
    "    POS_SIGMA = 1.0\n",
    "    VEL_SIGMA = 0.5\n",
    "    noise = np.concatenate(\n",
    "        (\n",
    "            np.random.normal(0.0, POS_SIGMA, (NUM_PARTICLES,1)),\n",
    "            np.random.normal(0.0, POS_SIGMA, (NUM_PARTICLES,1)),\n",
    "            np.random.normal(0.0, VEL_SIGMA, (NUM_PARTICLES,1)),\n",
    "            np.random.normal(0.0, VEL_SIGMA, (NUM_PARTICLES,1))\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    particles += noise\n",
    "    return particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(frame, particles, location):\n",
    "    if len(particles) > 0:\n",
    "        for i in range(NUM_PARTICLES):\n",
    "            x = int(particles[i,0])\n",
    "            y = int(particles[i,1])\n",
    "#            cv2.circle(frame, (x,y), 1, (0,255,0), 1)\n",
    "    if len(location) > 0:\n",
    "        cv2.circle(frame, location, 15, (0,0,255), 5)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(30) == 27: # wait n msec for user to his Esc key\n",
    "        if cv2.waitKey(0) == 27: # second Esc key exits program\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = initialize_particles()\n",
    "\n",
    "for frame in get_frames(VFILENAME):\n",
    "    if frame is None: break\n",
    "\n",
    "    particles = apply_velocity(particles)\n",
    "    particles = enforce_edges(particles)\n",
    "    errors = compute_errors(particles, frame)\n",
    "    weights = compute_weights(errors)\n",
    "    particles, location = resample(particles, weights)\n",
    "    particles = apply_noise(particles)\n",
    "    terminate = display(frame, particles, location)\n",
    "    if terminate:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: What is the purpose of casting the particle x and y positions to integers?\n",
    "- Floating point values are not allowed for indexing a numpy index.\n",
    "- So they can be used as pixel coordinates in the current video frame.\n",
    "\n",
    "Q2: Which of the following is not a good reason for initializing all the particles with random positions and velocities:\n",
    "To prevent them from collapsing onto a single pixel.\n",
    "\n",
    "Q3: To prevent the pixels from going off the edge of the video frames, we:\n",
    "place upper and lower bounds on their values\n",
    "\n",
    "Q4: Which of the following is not true of the mean squared color errors we calculated:\n",
    "the error will be zero for particles on top of the target\n",
    "\n",
    "\n",
    "Q5: To prevent pixels from piling up on the edge of the video frames, we:\n",
    "set their weights to zero\n",
    "\n",
    "Q6: The reason our program crashed with NaN values in probability distribution is because we had weight values of zero, causing a divide-by-zero error. False\n",
    "\n",
    "Q7: If we decided there was more uncertainty about the target's state in the next frame, we could handle this by:\n",
    "increasing POS_SIGMA and VEL_SIGMA\n",
    "\n",
    "Q8: The particle cloud spreads out when the target is occluded because:\n",
    "- none of the particles are located over pixels with a good colour match\n",
    "- there is less difference in particles weights, so they all get resampled more uniformly\n",
    "- the probability distribution over the particles is more uniform\n",
    "- there is growing uncertainty about the state of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
